{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root, filename)\n",
    "\n",
    "            inBody = False\n",
    "            lines = []\n",
    "            f = io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody = True\n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(filename)\n",
    "\n",
    "    return DataFrame(rows, index=index)\n",
    "\n",
    "data = DataFrame({'message': [], 'class': []}) # creates an empty df\n",
    "\n",
    "data = pd.concat([data, dataFrameFromDirectory(\"C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\", \"spam\")]);\n",
    "data = pd.concat([data, dataFrameFromDirectory(\"C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/ham\", \"ham\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\\00001.7848dde101aa985090474a91ec93fcf0</th>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\\00002.d94f1b97e48ed3b553b3508d116e6a09</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\\00003.2ee33bc6eacdb11f38d052c44819ba6c</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\\00004.eac8de8d759b7e74154f142194282724</th>\n",
       "      <td>##############################################...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\\00005.57696a39d7d84318ce497886896bf90d</th>\n",
       "      <td>I thought you might like these:\\n\\n1) Slim Dow...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              message  \\\n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...   \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...   \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  ##############################################...   \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  I thought you might like these:\\n\\n1) Slim Dow...   \n",
       "\n",
       "                                                   class  \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  spam  \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  spam  \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  spam  \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  spam  \n",
       "C:/Users/ahmad/OneDrive/Documents/Machine Learn...  spam  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call <b><u>vectorization</u></b> the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or “Bag of n-grams” representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(data['message'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier for multinomial models.\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = ['Free Viagra now!!!', \"Hi Bob, how about a game of golf tomorrow?\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Used ChatGPT to transform the original code to a more \"beginner\" friendly code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 'Free Viagra now!!!' is predicted as 'spam'\n",
      "Example: 'Hi Bob, how about a game of golf tomorrow?' is predicted as 'normal'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Function to read emails from a directory\n",
    "def read_emails(directory_path, label):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        with open(os.path.join(directory_path, filename), mode='r', encoding='latin1') as file:\n",
    "            content = file.read()\n",
    "            data.append({'message': content, 'class': label, 'filename': filename})\n",
    "    return data\n",
    "\n",
    "# Function to create a DataFrame from a list of emails\n",
    "def create_dataframe(directory_path, label):\n",
    "    emails_data = read_emails(directory_path, label)\n",
    "    return pd.DataFrame(emails_data)\n",
    "\n",
    "# Paths to spam and ham (normal) email directories\n",
    "spam_path = \"C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/spam\"\n",
    "normal_path = \"C:/Users/ahmad/OneDrive/Documents/Machine Learning Course/MLCourse/emails/ham\"\n",
    "\n",
    "# Create DataFrames for spam and normal emails\n",
    "spam_df = create_dataframe(spam_path, 'spam')\n",
    "normal_df = create_dataframe(normal_path, 'normal')\n",
    "\n",
    "# Combine DataFrames into one\n",
    "data = pd.concat([spam_df, normal_df])\n",
    "\n",
    "# Vectorize the email messages\n",
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(data['message'].values)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)\n",
    "\n",
    "# Examples to classify\n",
    "examples = ['Free Viagra now!!!', \"Hi Bob, how about a game of golf tomorrow?\"]\n",
    "\n",
    "# Vectorize the examples\n",
    "example_counts = vectorizer.transform(examples)\n",
    "\n",
    "# Predict using the trained classifier\n",
    "predictions = classifier.predict(example_counts)\n",
    "\n",
    "# Print the predictions\n",
    "for example, prediction in zip(examples, predictions):\n",
    "    print(f\"Example: '{example}' is predicted as '{prediction}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
